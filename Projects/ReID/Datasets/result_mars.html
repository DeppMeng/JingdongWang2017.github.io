
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <script src="js/jquery.min.js"></script>
    <script src="js/common.js"></script>
    <script src="./js/bootstrap.min.js"></script>

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/custom.css" rel="stylesheet">
    <link href="css/no_left_indent.css" rel="stylesheet">
    <style>
      th i.glyphicon {
        padding-left: 1em;
        font-size: .5em;
      }
    </style>

    <script>
      $(function () {
        var colToSort = [1, 2, 3, 4, 5];
        $('table').each(function (_, $table) {
          // Ignore 500K Tables
          if ($table.id.indexOf('500k') >= 0) return;

          var $trs = $('tbody > tr', $table).clone();
          var $tbody = $('tbody', $table);
          var $headers = $('thead th', $table);
          var objs = [];
          var currentArr = [], remains = 0, currentObj = {};
          $trs.each(function (_, tr) {
            var $tr = $(tr);
            if (remains === 0) {
              remains = parseInt($('td', $tr).eq(0).attr('rowspan') || 1) - 1;
              currentArr.push($tr);
              $(colToSort).each(function (_, index) {
                var value = parseFloat($('td', $tr).eq(index).text().trim()) || -Infinity;
                currentObj[index] = value;
              })
            } else {
              currentArr.push($tr);
              $(colToSort).each(function (_, index) {
                if (index - 2 < 0) return;
                var value = parseFloat($('td', $tr).eq(index - 2).text().trim()) || -Infinity;
                if (value > currentObj[index]) currentObj[index] = value;
              })
              remains--;
            }
            if (remains === 0) {
              currentObj.element = $(currentArr);
              objs.push(currentObj);
              currentArr = [];
              currentObj = {};
            }
          });
          $headers.each(function (index, th) {
            if (colToSort.indexOf(index) < 0) return;
            var order = 1;
            $(th).css('cursor', 'pointer').data('toggle', 'tooltip').attr('title', 'click to sort')
                 .on('click', function () {

              $('thead i', $table).remove();
              if (order === 1)
                $('<i class="glyphicon glyphicon-triangle-bottom"></i>').appendTo(th);
              else
                $('<i class="glyphicon glyphicon-triangle-top"></i>').appendTo(th);

              objs.sort(function (obj1, obj2) {
                var a = obj1[index], b = obj2[index];
                return order * (a < b ? 1 : a === b ? 0 : -1);
              })
              order = -order;
              $tbody.html('');
              $(objs).each(function (_, obj) {
                obj.element.each(function (_, el) {
                  $(el).clone().appendTo($tbody);
                });
              });
            });
          })
        })
      })
    </script>
  </head>

  <body>
    <div id="nav-jumbo-placeholder"> </div>
    <div class="jumbotron">
            <div class="container">
            <div class="text-center">
                    <h1 style=color:aliceblue>Mars</h1>
                    <p style=color:aliceblue>The leaderboard</p>
                <!-- <p><a class="btn btn-primary btn-lg" href="registration.html" role="button">Register Now</a></p> -->
            </div>
            </div>
        </div>
    <div style="width: 1200px; margin:0 auto;">
      <h3>Baseline</h3>
      <table id="mars" class="table table-striped table-bordered" cellspacing="0" width="100%">
            <thead>
                <tr>
                    <th width="35%" rowspan="2"><strong>Paper Title</strong></th><th width="8%" rowspan="2"><strong>Year</strong></th>
                    <th>rank-1</th><th>rank-5</th><th>rank-20</th><th>mAP</th><th width="30%" style="text-align: center" rowspan="2"><strong>Notes</strong></th>
                </tr>
            </thead>
            <tbody>
            <tr>
            <td rowspan="7">MARS: A Video Benchmark for Large-Scale Person Re-identification<a href="#ref"> [1]</a></td> <td rowspan="7">2016</td><td>2.6</td><td>6.4</td><td>12.4</td><td>0.8</td> <td rowspan="1">HOG3D<a href="#ref8"> [11]</a> + kissme<a href="#ref9"> [12]</a>, Euclidean distance, single query</td>
            </tr>

            <tr>
                <td>1.2</td><td>2.8</td><td>7.4</td><td>0.4</td><td rowspan="1">GEI<a href="#ref10"> [13]</a> + kissme<a href="#ref9"> [12]</a>, single query. </td>
            </tr>
            <tr>
                <td>18.6</td><td>33.0</td><td>45.9</td><td>8.0</td><td rowspan="1">HistLBP<a href="#ref11"> [14]</a> + XQDA<a href="#ref12"> [15]</a>, single query</td>
            </tr>
            <tr>
                <td>30.6</td><td>46.2</td><td>59.2</td><td>15.5</td><td rowspan="1">BoW<a href="#ref13"> [16]</a> + kissme<a href="#ref9"> [12]</a>, single query</td>
            </tr>
            <tr>
                <td>60.0</td><td>77.9</td><td>87.9</td><td>42.4</td><td rowspan="1">IDE, average pooling, Euclidean distance, single  query</td>
            </tr>
            <tr>
                <td>65.0</td><td>81.1</td><td>88.9</td><td>45.6</td><td rowspan="1">IDE + kissme, max pooling, Euclidean distance, single query</td>
            </tr>
            <tr>
                <td>68.3</td><td>82.6</td><td>89.4</td><td>49.3</td><td rowspan="1">IDE + kissme, max pooling, Euclidean distance, multiple query</td>
            </tr>
        </tbody>
      </table>
        <h3>Results of supervised approaches</h3>
        <table id="mars" class="table table-striped table-bordered" cellspacing="0" width="100%">
            <thead>
                <tr>
                    <th width="35%" rowspan="2"><strong>Paper Title</strong></th><th width="8%" rowspan="2"><strong>Year</strong></th>
                    <th>rank-1</th><th>rank-5</th><th>rank-20</th><th>mAP</th><th width="30%" style="text-align: center" rowspan="2"><strong>Notes</strong></th>
                </tr>
            </thead>
            <tbody>
            <tr>
            <td>Learning Compact Appearance Representation for Video-based Person Re-Identification<a href="#ref"> [2]</a></td><td>2017</td> <td>55.5</td> <td>70.2</td> <td>80.2</td><td>-</td> <td>A frame selection step is used before feature pooling</td>
            </tr>
            <tr>
            <td>Multi-Target Tracking in Multiple Non-Overlapping Cameras using Constrained Dominant Sets<a href="#ref"> [3]</a></td><td>2017</td> <td>68.22</td> <td>-</td> <td>-</td><td>-</td> <td>The constrained dominant sets clustering (CDSC) method is proposed.</td>
            </tr>
            <tr>
            <td rowspan="2">Re-ranking Person Re-identification with k-reciprocal Encoding<a href="#ref1"> [4]</a></td><td rowspan="2">2017</td> <td>67.78</td> <td>-</td> <td>-</td><td>57.98</td><td>IDE (CaffeNet) + re-ranking, single query.  </td>
            </tr>
            <tr>
            <td>73.94</td> <td>-</td> <td>-</td><td>68.45</td><td> IDE (ResNet50) + re-ranking, single query. </td>
            </tr>

            <tr>
            <td rowspan="2">Learning Deep Context-aware Features over Body and Latent Parts for Person Re-identification<a href="#ref2"> [5]</a></td><td rowspan="2">2017</td> <td>71.77</td> <td>86.57</td> <td>93.08</td><td>56.05</td><td> Using the fine-tuned TriNet and Euclidean distance, single query. </td>
            </tr>
            <tr>
                <td>83.03</td> <td>93.69</td> <td>97.63</td><td>66.43</td><td>TriNet + re-ranking<a href="#ref14"> [17]</a></td>
            </tr>

            <tr>
            <td>See the forest for the trees: Joint spatial and temporal recurrent neural networks for video-based person re-identification<a href="#ref3"> [6]</a></td><td>2017</td> <td>70.6</td> <td>90.0</td> <td>97.6</td><td>50.7</td> <td>Single query. Handles both spatial and temporal information.</td>
            </tr>

            <tr>
            <td>Quality Aware Network for Set to Set Recognition<a href="#ref4"> [7]</a></td><td>2017</td> <td>73.74</td> <td>84.90</td> <td>91.62</td><td>51.70</td> <td>P-QAN (googlenet), single query. Numbers are provided by the authors, not reported in the paper</td>
            </tr>
            <tr>
            <td rowspan="2">In Defense of the Triplet Loss for Person Re-Identification<a href="#ref5"> [8]</a></td><td rowspan="2">2017</td> <td>79.80</td> <td>91.36</td> <td>-</td><td>67.70</td><td> Using the fine-tuned TriNet and Euclidean distance, single query. </td>
            </tr>
            <tr>
                <td>81.21</td> <td>90.76</td> <td>-</td><td>77.43</td><td>TriNet + re-ranking<a href="#ref14"> [17]</a></td>
            </tr>
            <tr>
            <td rowspan="1">Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification<a href="#ref15"> [18]</a></td><td rowspan="1">2018</td> <td>82.3</td> <td>-</td> <td>-</td><td>65.8</td><td> Multi-region spatial attention + temporal attention + fine-tuning, single query. </td>
            </tr>
            <tr>
            <td rowspan="1">Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning<a href="#ref16"> [19]</a></td><td rowspan="1">2018</td> <td>62.67</td> <td>74.94</td> <td>82.57</td><td>42.45</td><td> Backbone: ETAP-Net, baseline: initial model trained on one-shot labeled data. </td>
            </tr>
            <tr>
            <td rowspan="1">Dual Attention Matching Network for Context-Aware Feature Sequence Based Person Re-Identification<a href="#ref17"> [20]</a></td><td rowspan="1">2018</td> <td>78.74</td> <td>90.86</td> <td>95.76</td><td>62.26</td><td> Triplet loss + De-Correlation loss + Cross-entropy loss with data augmentation. </td>
            </tr>
            <tr>
            <td rowspan="1">Multi-Shot Pedestrian Re-Identification via Sequential Decision Making<a href="#ref18"> [21]</a></td><td rowspan="1">2018</td> <td>71.2</td> <td>85.7</td> <td>94.3</td><td>-</td><td>Inception-BN + proposed sequential decision making method. </td>
            </tr>
            <tr>
            <td rowspan="1">Mask-Guided Contrastive Attention Model for Person Re-Identification<a href="#ref19"> [22]</a></td><td rowspan="1">2018</td> <td>77.17</td> <td>-</td> <td>-</td><td>71.17</td><td>Proposed MGCAM-Siamese model. </td>
            </tr>
            <tr>
            <td rowspan="1">Video Person Re-Identification With Competitive Snippet-Similarity Aggregation and Co-Attentive Snippet Embedding<a href="#ref20"> [23]</a></td><td rowspan="1">2018</td> <td>86.3</td> <td>94.7</td> <td>98.2</td><td>76.1</td><td></td>
            </tr>
            <tr>
            <td rowspan="2">Part-Aligned Bilinear Representations for Person Re-Identification<a href="#ref23"> [26]</a></td><td rowspan="2">2018</td> <td>84.7</td> <td>94.4</td> <td>97.5</td><td>75.9</td><td>Inception-V1 (with dilation filters from inception4a to final layer) + OpenPose.</td>
            </tr>
            <tr>
                <td>85.1</td> <td>94.2</td> <td>97.4</td><td>83.9</td><td>Inception-V1 (with dilation filters from inception4a to final layer) + OpenPose + re-ranking.</td>
            </tr>
            <tr>
            <td rowspan="2">Person Re-identification with Hierarchical Deep Learning Feature and efficient XQDA Metric<a href="#ref24"> [27]</a></td><td rowspan="2">2018</td> <td>86.4</td> <td>96.1</td> <td>-</td><td>79.3</td><td>HDLF.</td>
            </tr>
            <tr>
                <td>87.6</td> <td>95.8</td> <td>-</td><td>85.8</td><td>HDLF + re-ranking.</td>
            </tr>
            <tr>
            <td rowspan="1">Video-based Person Re-identification via Self-Paced Learning and Deep Reinforcement Learning Framework<a href="#ref25"> [28]</a></td><td rowspan="1">2018</td> <td>74.8</td> <td>86.7</td> <td>-</td><td>-</td><td>-</td>
            </tr>
        </tbody></table>

      </table>
      <h3>Results of unsupervised/transfer learning</h3>
      <table id="mars" class="table table-striped table-bordered" cellspacing="0" width="100%">
            <thead>
                <tr>
                    <th width="35%" rowspan="2"><strong>Paper Title</strong></th><th width="8%" rowspan="2"><strong>Year</strong></th>
                    <th>rank-1</th><th>rank-5</th><th>rank-20</th><th>mAP</th><th width="30%" style="text-align: center" rowspan="2"><strong>Notes</strong></th>
                </tr>
            </thead>
            <tbody>
          <tr>
          <td rowspan="1">Robust Anchor Embedding for Unsupervised Video Person Re-Identification in the Wild<a href="#ref21"> [24]</a></td><td rowspan="1">2018</td> <td>41.0</td> <td>55.6</td> <td>67.2</td><td>22.3</td><td>Unsupervised setting.</td>
          </tr>
          <tr>
          <td rowspan="1">Unsupervised Person Re-identification by Deep Learning Tracklet Association<a href="#ref22"> [25]</a></td><td rowspan="1">2018</td> <td>43.8</td> <td>59.9</td> <td>72.8</td><td>29.1</td><td>Unsupervised setting.</td>
          </tr>
      </tbody></table>
        <h3>Use the dataset for training, but do not report results/using a different evaluation protocol</h3>
        <table id="mars" class="table table-striped table-bordered" cellspacing="0" width="100%">
            <thead>
                <tr>
                    <th width="35%" rowspan="2"><strong>Paper Title</strong></th><th width="8%" rowspan="2"><strong>Year</strong></th>
                    <th>rank-1</th><th>rank-5</th><th>rank-20</th><th>mAP</th><th width="30%" style="text-align: center" rowspan="2"><strong>Notes</strong></th>
                </tr>
            </thead>
            <tbody>
            <tr>
            <td>Simple Online and Realtime Tracking with a Deep Association Metric<a href="#ref6"> [9]</a></td><td>2017</td> <td>-</td> <td>-</td> <td>-</td><td>-</td><td>The CNN model is trained on MARS </td>
            </tr>
            <tr>
            <td>Jointly Attentive Spatial-Temporal Pooling Networks for Video-based Person Re-Identification<a href="#ref7"> [10]</a></td><td>2017</td> <td>44</td> <td>70</td> <td>81</td><td>-</td> <td>Single query. Joint Spatial and Temporal Attention Pooling Network. The evaluation protocol is different from the original one.</td>
            </tr>

        </tbody></table>
        <h2 id="ref">References</h2>
        <ul style="list-style-type:none">
            <li id="ref1"> [1] "MARS: A Video Benchmark for Large-Scale Person Re-identification", L. Zheng, Z. Bie, Y. Sun, J. Wang, C. Su, S. Wang, and Q. Tian, ECCV 2016.</li>
            <li id="ref2"> [2] "Learning Compact Appearance Representation for Video-based Person Re-Identification", Wei Zhang, Shengnan Hu, Kan Liu, Arxiv 2017.</li>
            <li id="ref3"> [3] "Multi-Target Tracking in Multiple Non-Overlapping Cameras using Constrained Dominant Sets", Yonatan Tariku Tesfaye, Eyasu Zemene, Andrea Prati, Marcello Pelillo, and Mubarak Shah, Arxiv 2017.</li>
            <li id="ref4"> [4] "Re-ranking Person Re-identification with k-reciprocal Encoding", Z. Zhong, L. Zheng, D. Cao, and S. Li, CVPR 2017.</li>
            <li id="ref5"> [5] "Learning Deep Context-aware Features over Body and Latent Parts for Person Re-identification", Dangwei Li, Xiaotang Chen, Zhang Zhang, Kaiqi Huang, CVPR 2017.</li>
            <li id="ref6"> [6] "See the forest for the trees: Joint spatial and temporal recurrent neural networks for video-based person re-identification", Zhen Zhou, Yan Huang, Wei Wang, Liang Wang, and Tieniu Tan, CVPR 2017.</li>
            <li id="ref7"> [7] "Quality Aware Network for Set to Set Recognition", Yu Liu, Junjie Yan, Wanli Ouyang, CVPR 2017.</li>
            <li id="ref8"> [8] "In Defense of the Triplet Loss for Person Re-Identification", Alexander Hermans, Lucas Beyer and Bastian Leibe, Arxiv 2017.</li>
            <li id="ref9"> [9] "Simple Online and Realtime Tracking with a Deep Association Metric", Nicolai Wojke, Alex Bewley, Dietrich Paulus, ArXiv 2017.</li>
            <li id="ref10"> [10] "Jointly Attentive Spatial-Temporal Pooling Networks for Video-based Person Re-Identification", Shuangjie Xu, Yu Cheng, Kang Gu, Yang Yang, Shiyu Chang, Pan Zhou, ICCV 2017.</li>
            <li id="ref11"> [11] "A spatio-temporal descriptor based on 3d gradients", Alexander Klaser, Marcin Marszalek, Cordelia Schmid, BMCV 2008. </li>
            <li id="ref12"> [12] "Large scale metric learning from equivalence constraints", Martin Köstinger, Martin Hirzer, Paul Wohlhart, Peter M. Roth, Horst Bischof, CVPR 2012</li>
            <li id="ref13"> [13] "Individual recognition using gait energy image", Ju Man, Bir Bhanu, TPAMI 2006.</li>
            <li id="ref14"> [14] "Person reidentification using kernel-based metric learning methods", F. Xiong, M. Gou, O. Camps, and M. Sznaier, ECCV 2014.</li>
            <li id="ref15"> [15] "Person re-identification by local maximal occurrence representation and metric learning", S. Liao, Y. Hu, X. Zhu, and S. Z. Li, CVPR 2015.</li>
            <li id="ref16"> [16] "Scalable person re-identification: a benchmark", Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, Qi Tian, ICCV 2015.</li>
            <li id="ref17"> [17] "Re-ranking Person Re-identification with k-reciprocal Encoding", Z. Zhong, L. Zheng, D. Cao, and S. Li, CVPR 2017.</li>
            <li id="ref18"> [18] "Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification", Shuang Li, Slawomir Bak, Peter Carr, Xiaogang Wang, CVPR 2018.</li>
            <li id="ref19"> [19] "Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning", Yu Wu, Yutian Lin, Xuanyi Dong, Yan Yan, Wanli Ouyang, Yi Yang, CVPR 2018.</li>
            <li id="ref20"> [20] "Dual Attention Matching Network for Context-Aware Feature Sequence Based Person Re-Identification", Jianlou Si, Honggang Zhang, Chun-Guang Li, Jason Kuen, Xiangfei Kong, Alex C. Kot, Gang Wang, CVPR 2018.</li>
            <li id="ref21"> [21] "Multi-Shot Pedestrian Re-Identification via Sequential Decision Making", Jianfu Zhang, Naiyan Wang, Liqing Zhang, CVPR 2018.</li>
            <li id="ref22"> [22] "Mask-guided Contrastive Attention Model for Person Re-Identification", Chunfeng Song, Yan Huang, Wanli Ouyang, Liang Wang, CVPR 2018.</li>
            <li id="ref23"> [23] "Video Person Re-identification with Competitive Snippet-similarity Aggregation and Co-attentive Snippet Embedding", Dapeng Chen, Hongsheng Li, Tong Xiao, Shuai Yi, Xiaogang Wang, CVPR 2018.</li>
            <li id="ref24"> [24] "Robust Anchor Embedding for Unsupervised Video Person Re-Identification in the Wild",Mang Ye, Xiangyuan Lan, Pong C. Yuen, ECCV 2018.</li>
            <li id="ref25"> [25] "Unsupervised Person Re-identification by Deep Learning Tracklet Association", Minxian Li, Xiatian Zhu, Shaogang Gong, ECCV 2018.</li>
            <li id="ref26"> [26] "Part-Aligned Bilinear Representations for Person Re-Identification", Yumin Suh, Jingdong Wang, Siyu Tang, Tao Mei, Kyoung Mu Lee, ECCV 2018.</li>
            <li id="ref27"> [27] "Person Re-identification with Hierarchical Deep Learning Feature and efficient XQDA Metric", Mingyong Zeng, Chang Tian, Zemin Wu, ACM MM 2018.</li>
            <li id="ref28"> [28] "Video-based Person Re-identification via Self-Paced Learning and Deep Reinforcement Learning Framework", Deqiang Ouyang, Jie Shao, Yonghui Zhang, Yang Yang, Heng Tao Shen, ACM MM 2018.</li>

        </ul>
    	<div id="footer"> </div>
    </div>

  </body>
</html>
